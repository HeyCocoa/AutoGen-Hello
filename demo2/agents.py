"""
AutoGen Agents å®šä¹‰ï¼ˆé€‚é… autogen 0.4.2ï¼‰
æ‰‹åŠ¨å®ç° RAG æ£€ç´¢é€»è¾‘
"""
import asyncio
import chromadb
from chromadb.config import Settings
from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.ui import Console
from autogen_agentchat.conditions import TextMentionTermination
from autogen_agentchat.teams import RoundRobinGroupChat
from autogen_ext.models.openai import OpenAIChatCompletionClient

from config import LLM_CONFIG, CHROMADB_PATH, COLLECTION_NAME
from embedding_client import SiliconFlowEmbedding


class RAGAssistant:
    """å¸¦ RAG èƒ½åŠ›çš„é€‰é¢˜åŠ©æ‰‹"""

    def __init__(self):
        # åˆå§‹åŒ– Chromadb å®¢æˆ·ç«¯
        self.chroma_client = chromadb.PersistentClient(
            path=str(CHROMADB_PATH),
            settings=Settings(anonymized_telemetry=False)
        )
        self.embedding_function = SiliconFlowEmbedding()

        # è·å–é›†åˆ
        try:
            self.collection = self.chroma_client.get_collection(
                name=COLLECTION_NAME,
                embedding_function=self.embedding_function
            )
            print(f"âœ… æˆåŠŸè¿æ¥åˆ°çŸ¥è¯†åº“: {COLLECTION_NAME}")
        except Exception as e:
            print(f"âŒ æ— æ³•è¿æ¥åˆ°çŸ¥è¯†åº“: {e}")
            print("è¯·å…ˆè¿è¡Œ: python init_db.py")
            raise

        # åˆ›å»º LLM å®¢æˆ·ç«¯
        model_client = OpenAIChatCompletionClient(
            model=LLM_CONFIG["config_list"][0]["model"],
            api_key=LLM_CONFIG["config_list"][0]["api_key"],
            base_url=LLM_CONFIG["config_list"][0]["base_url"],
            model_info={
                "vision": False,
                "function_calling": True,
                "json_output": False,
            }
        )

        # åˆ›å»º AssistantAgent
        self.agent = AssistantAgent(
            name="é€‰é¢˜ç­–åˆ’å¸ˆ",
            model_client=model_client,
            system_message="""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ç§‘æŠ€åª’ä½“é€‰é¢˜ç­–åˆ’å¸ˆã€‚

ä½ çš„èŒè´£æ˜¯ï¼š
1. æ ¹æ®ç”¨æˆ·è¾“å…¥çš„è¡Œä¸šå…³é”®è¯ï¼Œç»“åˆæä¾›çš„å†å²é€‰é¢˜ç­–ç•¥å’Œè¡Œä¸šèƒŒæ™¯çŸ¥è¯†
2. ç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„é€‰é¢˜å»ºè®®ï¼ŒåŒ…æ‹¬ï¼š
   - é€‰é¢˜æ–¹å‘ï¼ˆ3-5ä¸ªå…·ä½“é€‰é¢˜ï¼‰
   - å†…å®¹è¦ç‚¹ï¼ˆæ¯ä¸ªé€‰é¢˜çš„æ ¸å¿ƒå†…å®¹ï¼‰
   - ç›®æ ‡å—ä¼—
   - é¢„æœŸæ•ˆæœ

è¯·ç”¨ä¸“ä¸šã€ç®€æ´çš„è¯­è¨€å›å¤ï¼Œçªå‡ºå®ç”¨æ€§å’Œå¯æ“ä½œæ€§ã€‚
å¦‚æœæä¾›çš„èƒŒæ™¯çŸ¥è¯†ä¸è¶³ï¼Œè¯·æ˜ç¡®æŒ‡å‡ºç¼ºå°‘å“ªæ–¹é¢çš„ä¿¡æ¯ã€‚""",
        )

        print("âœ… RAG Assistant åˆå§‹åŒ–æˆåŠŸ")

    def retrieve_knowledge(self, keyword: str, n_results: int = 5) -> str:
        """
        ä»çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³å†…å®¹

        Args:
            keyword: æŸ¥è¯¢å…³é”®è¯
            n_results: è¿”å›ç»“æœæ•°é‡

        Returns:
            æ ¼å¼åŒ–çš„æ£€ç´¢ç»“æœ
        """
        print(f"\nğŸ” æ­£åœ¨æ£€ç´¢å…³é”®è¯: {keyword}")

        try:
            results = self.collection.query(
                query_texts=[keyword],
                n_results=n_results
            )

            if not results['ids'][0]:
                return "âš ï¸ æœªæ‰¾åˆ°ç›¸å…³çŸ¥è¯†ï¼Œå»ºè®®è¡¥å……è¯¥é¢†åŸŸçš„èƒŒæ™¯ä¿¡æ¯ã€‚"

            # æ ¼å¼åŒ–æ£€ç´¢ç»“æœ
            knowledge_text = f"ğŸ“š æ£€ç´¢åˆ° {len(results['ids'][0])} æ¡ç›¸å…³çŸ¥è¯†ï¼š\n\n"

            for i, (doc_id, doc, metadata, distance) in enumerate(zip(
                results['ids'][0],
                results['documents'][0],
                results['metadatas'][0],
                results['distances'][0]
            ), 1):
                similarity = 1 - distance
                knowledge_text += f"[{i}] å…³é”®è¯: {metadata['keyword']} | ç±»åˆ«: {metadata['category']} | ç›¸ä¼¼åº¦: {similarity:.2%}\n"
                knowledge_text += f"{doc}\n\n"

            print(f"âœ… æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(results['ids'][0])} æ¡ç»“æœ")
            return knowledge_text

        except Exception as e:
            print(f"âŒ æ£€ç´¢å¤±è´¥: {e}")
            return f"âŒ æ£€ç´¢å¤±è´¥: {str(e)}"

    async def generate_topic_suggestion(self, keyword: str) -> str:
        """
        ç”Ÿæˆé€‰é¢˜å»ºè®®

        Args:
            keyword: ç”¨æˆ·è¾“å…¥çš„å…³é”®è¯

        Returns:
            é€‰é¢˜å»ºè®®æ–‡æœ¬
        """
        # 1. æ£€ç´¢ç›¸å…³çŸ¥è¯†
        knowledge = self.retrieve_knowledge(keyword, n_results=5)

        # 2. æ„é€ æç¤ºè¯
        prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹å…³é”®è¯å’ŒèƒŒæ™¯çŸ¥è¯†ï¼Œç”Ÿæˆä¸“ä¸šçš„é€‰é¢˜å»ºè®®ï¼š

**å…³é”®è¯**: {keyword}

**èƒŒæ™¯çŸ¥è¯†**:
{knowledge}

è¯·ç”Ÿæˆé€‰é¢˜å»ºè®®ã€‚"""

        # 3. è°ƒç”¨ Agent ç”Ÿæˆå›å¤
        print("\nğŸ’¡ æ­£åœ¨ç”Ÿæˆé€‰é¢˜å»ºè®®...")

        response = await self.agent.on_messages(
            [{"content": prompt, "source": "user"}],
            cancellation_token=None
        )

        return response.chat_message.content

    async def chat_interactive(self, keyword: str):
        """
        äº¤äº’å¼å¯¹è¯ï¼ˆæ”¯æŒå¤šè½®ï¼‰

        Args:
            keyword: åˆå§‹å…³é”®è¯
        """
        # æ£€ç´¢çŸ¥è¯†
        knowledge = self.retrieve_knowledge(keyword, n_results=5)

        # æ„é€ åˆå§‹æ¶ˆæ¯
        initial_message = f"""è¯·æ ¹æ®å…³é”®è¯"{keyword}"ç”Ÿæˆé€‰é¢˜å»ºè®®ã€‚

èƒŒæ™¯çŸ¥è¯†ï¼š
{knowledge}"""

        # åˆ›å»ºç»ˆæ­¢æ¡ä»¶
        termination = TextMentionTermination("TERMINATE")

        # åˆ›å»ºå• Agent å›¢é˜Ÿ
        team = RoundRobinGroupChat(
            [self.agent],
            termination_condition=termination,
        )

        # è¿è¡Œå¯¹è¯
        await Console(team.run_stream(task=initial_message))


def create_rag_assistant():
    """åˆ›å»º RAG Assistant å®ä¾‹"""
    return RAGAssistant()


# åŒæ­¥åŒ…è£…å‡½æ•°
def generate_topic_sync(keyword: str) -> str:
    """åŒæ­¥ç‰ˆæœ¬çš„é€‰é¢˜ç”Ÿæˆ"""
    assistant = create_rag_assistant()
    result = asyncio.run(assistant.generate_topic_suggestion(keyword))
    return result


if __name__ == "__main__":
    # æµ‹è¯•
    print("ğŸ§ª æµ‹è¯• RAG Assistant...")
    assistant = create_rag_assistant()
    result = asyncio.run(assistant.generate_topic_suggestion("AIå¤§æ¨¡å‹"))
    print("\n" + "="*60)
    print(result)
